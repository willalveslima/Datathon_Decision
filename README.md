# Sistema de Recomenda√ß√£o de Candidatos para Vagas

Este projeto implementa um sistema de recomenda√ß√£o de candidatos para vagas de emprego, utilizando um modelo de Machine Learning (ML) e uma arquitetura baseada em microsservi√ßos com FastAPI, PostgreSQL, Prometheus e Grafana. O pipeline de MLOps inclui pr√©-processamento de dados, treinamento de modelo, API de predi√ß√£o, servi√ßo de monitoramento de drift e um pipeline de CI/CD automatizado com GitHub Actions e Google Cloud Platform (GCP).

## üöÄ Funcionalidades

* **Recomenda√ß√£o de Candidatos**: Previs√£o da probabilidade de um candidato ser contratado para uma vaga espec√≠fica.
* **Engenharia de Features Avan√ßada**: Utiliza TF-IDF e extra√ß√£o de habilidades/tecnologias de dados textuais, al√©m de features categ√≥ricas e de localiza√ß√£o.
* **API RESTful de Predi√ß√£o**: Endpoint para receber dados de vagas e candidatos e retornar um ranking de probabilidades.
* **Servi√ßo de Coleta de Feedback**: Endpoint para registrar o resultado real das contrata√ß√µes, essencial para o monitoramento de drift.
* **Monitoramento de Drift do Modelo**: C√°lculo agendado de m√©tricas de Data Drift (mudan√ßa na distribui√ß√£o dos dados de entrada) e Concept Drift (queda de desempenho do modelo).
* **Monitoramento de Aplica√ß√£o**: Coleta de m√©tricas HTTP (lat√™ncia, requisi√ß√µes, erros) de todos os servi√ßos usando Prometheus e Grafana.
* **Persist√™ncia de Dados**: Armazenamento de logs de predi√ß√£o e m√©tricas de drift em um banco de dados PostgreSQL.
* **CI/CD Automatizado**: Pipeline de Integra√ß√£o Cont√≠nua e Implanta√ß√£o Cont√≠nua com GitHub Actions para automatizar testes, builds e deploys na GCP.


## üèõÔ∏è Arquitetura

O projeto √© dividido em v√°rios componentes, orquestrados via Docker Compose para desenvolvimento local e implantados na Google Cloud Platform para produ√ß√£o.

* **API de Predi√ß√£o (FastAPI)**:
    * Recebe requisi√ß√µes de predi√ß√£o.
    * Aplica pr√©-processamento e infer√™ncia do modelo.
    * Salva logs de predi√ß√£o no PostgreSQL.
    * Exp√µe m√©tricas Prometheus.
    * Implantada no **Google Cloud Run**.
* **Servi√ßo de Monitoramento de Drift (FastAPI)**:
    * Recebe feedback sobre o resultado real das contrata√ß√µes.
    * Atualiza logs de predi√ß√£o no PostgreSQL.
    * Executa um job agendado para calcular m√©tricas de drift.
    * Salva m√©tricas de drift no PostgreSQL.
    * Exp√µe m√©tricas Prometheus.
    * Implantada no **Google Cloud Run**.
* **Banco de Dados (PostgreSQL)**:
    * Armazena logs de predi√ß√£o e m√©tricas de drift.
    * Utiliza **Google Cloud SQL (PostgreSQL)**.
* **Prometheus**:
    * Coleta m√©tricas dos servi√ßos da API e de Drift Monitor.
    * Executado em uma **Imagem Docker** (para deploy local simplificado).
* **Grafana**:
    * Visualiza as m√©tricas coletadas pelo Prometheus.
    * Pain√©is para monitorar a sa√∫de da aplica√ß√£o e o drift do modelo.
    * Executado em uma **Imagem Docker** (para deploy local simplificado).
* **Google Cloud Storage**:
    * Armazena dados brutos e artefatos de modelo (modelos `.pkl`, vetorizadores).
* **Google Artifact Registry**:
    * Registro privado para imagens Docker constru√≠das.

## ‚öôÔ∏è Come√ßando (Setup Local)

Siga estes passos para configurar e rodar o projeto em sua m√°quina local.

### Pr√©-requisitos

* [Python 3.11](https://www.python.org/downloads/)
* [Docker Desktop](https://www.docker.com/products/docker-desktop/) (inclui Docker Compose)
* [Google Cloud CLI (gcloud)](https://cloud.google.com/sdk/docs/install)

### 1. Clonar o Reposit√≥rio

```bash
git clone [https://github.com/willalveslima/Datathon_Decision.git](https://github.com/willalveslima/Datathon_Decision.git)
cd Datathon_Decision
```

### 2. Configurar Ambiente Virtual e Ferramentas

Este script ir√° criar um ambiente virtual Python (`.venv`), instalar as depend√™ncias, configurar os hooks de pr√©-commit e criar os arquivos de configura√ß√£o para `isort`, `black` e `pylint`.

```bash
./.conf/setup_env.sh
```

### 3. Preparar Dados Brutos

Os dados brutos (`applicants.json`, `vagas.json`, `prospects.json`) devem ser colocados na pasta `data/raw/`. Se eles n√£o estiverem no seu reposit√≥rio Git, voc√™ precisar√° baix√°-los manualmente para `data/raw/`.

### 4. Executar Pr√©-processamento de Dados

Este passo gera o arquivo `data/processed/merged_data_processed.csv`.

```bash
python src/training/data_preprocessing_merge.py
```

### 5. Treinar o Modelo

Este passo treina o modelo de ML e salva os artefatos (modelo, vetorizadores, etc.) na pasta `models/`.

```bash
python src/training/model_training.py
```

### 6. Configurar Vari√°veis de Ambiente do Banco de Dados

Crie um arquivo `.env` na **raiz do seu projeto** com as credenciais do banco de dados (mesmas usadas no Cloud SQL para compatibilidade).

```
# .env
DB_NAME=ml_drift_db
DB_USER=ml_user
DB_PASSWORD=ml_password_secure
```

### 7. Iniciar a Stack Local

Este comando ir√° construir as imagens Docker (se necess√°rio) e iniciar todos os servi√ßos (API, Drift Monitor, PostgreSQL, Prometheus, Grafana) via Docker Compose.

```bash
./run_local.sh
```

### 8. Acessar os Servi√ßos Localmente

* **API de Predi√ß√£o**: `http://localhost:8000` (documenta√ß√£o Swagger em `http://localhost:8000/docs`)
* **Servi√ßo de Monitoramento de Drift**: `http://localhost:8001` (documenta√ß√£o Swagger em `http://localhost:8001/docs`)
* **Prometheus**: `http://localhost:9090`
* **Grafana**: `http://localhost:3000` (usu√°rio: `admin`, senha: `grafana-api`)

### 9. Testar o Pipeline Funcional Completo

Execute este script para simular requisi√ß√µes de predi√ß√£o e feedback, alimentando o banco de dados e as m√©tricas de drift. Ele rodar√° em loop at√© ser interrompido (`Ctrl+C`).

```bash
python tests/functional/test_full_pipeline.py
```

### 10. Parar a Stack Local

```bash
./stop_local.sh
```

## üå≥ Estrutura do Projeto

```
.
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ .env
‚îú‚îÄ‚îÄ run_local.sh
‚îú‚îÄ‚îÄ stop_local.sh
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ .pre-commit-config.yaml
‚îú‚îÄ‚îÄ pyproject.toml
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ applicants.json
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vagas.json
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ prospects.json
‚îÇ   ‚îî‚îÄ‚îÄ processed/
‚îÇ       ‚îî‚îÄ‚îÄ merged_data_processed.csv
‚îÇ
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ logistic_regression_model.pkl
‚îÇ   ‚îú‚îÄ‚îÄ tfidf_vectorizer_applicant.pkl
‚îÇ   ‚îú‚îÄ‚îÄ tfidf_vectorizer_job.pkl
‚îÇ   ‚îú‚îÄ‚îÄ categorical_cols.pkl
‚îÇ   ‚îú‚îÄ‚îÄ encoded_feature_names.pkl
‚îÇ   ‚îú‚îÄ‚îÄ common_skills.pkl
‚îÇ   ‚îî‚îÄ‚îÄ model_version.txt
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ training/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_preprocessing_merge.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model_training.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ prediction_service/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ prediction_service.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py # Para importa√ß√£o do app
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ drift_monitor_service/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py # Para importa√ß√£o do app
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îî‚îÄ‚îÄ common_utils.py
‚îÇ
‚îú‚îÄ‚îÄ docker/
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile 
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ drift_monitor/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ prometheus/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ prometheus.yml
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ grafana/
‚îÇ       ‚îú‚îÄ‚îÄ grafana.ini
‚îÇ       ‚îú‚îÄ‚îÄ datasources/
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ prometheus.yml
‚îÇ       ‚îî‚îÄ‚îÄ dashboards/
‚îÇ
‚îÇ
‚îî‚îÄ‚îÄ tests/
    ‚îú‚îÄ‚îÄ unit/
    ‚îÇ   ‚îú‚îÄ‚îÄ test_api.py
    ‚îÇ   ‚îú‚îÄ‚îÄ test_data_preprocessing.py    
    ‚îÇ   ‚îú‚îÄ‚îÄ test_model_training.py    
    ‚îÇ   ‚îî‚îÄ‚îÄ test_drift_monitor.py
    ‚îú‚îÄ‚îÄ functional/
    ‚îÇ   ‚îú‚îÄ‚îÄ test_full_pipilene_GCP.py
    ‚îÇ   ‚îî‚îÄ‚îÄ test_full_pipeline.py
    ‚îî‚îÄ‚îÄ .gitkeep
```
##  üßê Testes Automatizados e Verifica√ß√£o da Qualidade do C√≥digo

O projeto utiliza o pre-commit para verificar qualidade do c√≥digo e Teste automatizado:

```
repos:
- repo: local
  hooks:
  - id: isort
    name: Run isort
    types: [python]
    exclude: ^tests/
    entry: isort
    language: system
  - id: black
    name: Run black
    types: [python]
    exclude: ^tests/
    entry: black
    language: system
    args: ["--line-length=100"]
  - id: pydocstyle
    name: Roda pydocstyle
    types: [python]
    exclude: ^tests/
    entry: pydocstyle
    language: system
  - id: pylint
    name: Roda pylint
    types: [python]
    exclude: ^tests/
    entry: pylint
    language: system
  - id: pytest
    name: Roda pytest
    entry: bash -c "PYTHONPATH=. python -m pytest"
    language: system
    pass_filenames: false
    always_run: true
```


## üöÄ CI/CD com GitHub Actions e GCP

O projeto utiliza GitHub Actions para automatizar o pipeline de CI/CD, desde a valida√ß√£o do c√≥digo at√© o deploy dos servi√ßos no Google Cloud Platform.

### Vis√£o Geral do Pipeline (`.github/workflows/main.yml`)

1.  **Gatilhos**: `push` para `main`, `develop`, `feature/*` e `pull_request`.
2.  **Autentica√ß√£o GCP**: Autentica o GitHub Actions na GCP usando uma Service Account Key (`secrets.GCP_SA_KEY`).
3.  **Setup Python e Depend√™ncias**: Configura o ambiente Python e instala todas as depend√™ncias.
4.  **Download de Dados Brutos**: Baixa os arquivos JSON brutos do **Cloud Storage** (`gs://datathon-decision/raw/`) para o ambiente da Action.
5.  **Pr√©-processamento de Dados**: Executa `src/training/data_preprocessing_merge.py` para gerar o CSV processado.
6.  **Treinamento do Modelo**: Executa `src/training/model_training.py` para treinar o modelo e salvar os artefatos (`.pkl`, `.txt`) na pasta `models/` do runner.
7.  **Upload de Artefatos do Modelo**: Faz o upload dos modelos treinados da pasta `models/` do runner para o **Cloud Storage** (`gs://datathon-decision/models/`).
8.  **Testes com Cobertura**: Roda `pytest` com `pytest-cov` e imp√µe um limite m√≠nimo de cobertura.
9. **Build de Imagens Docker**: Constr√≥i as imagens Docker para a API e o Servi√ßo de Drift usando `Dockerfile.ci` (que baixam os modelos do GCS).
10. **Push de Imagens Docker**: Envia as imagens constru√≠das para o **Artifact Registry** da GCP.
11. **Deploy para Cloud Run**: Implanta as novas vers√µes da API de Predi√ß√£o e do Servi√ßo de Monitoramento de Drift no **Google Cloud Run**, passando as vari√°veis de ambiente do DB via GitHub Secrets.

### Configura√ß√£o de Segredos (GitHub Secrets)

Para que o pipeline funcione, voc√™ deve configurar os seguintes segredos no seu reposit√≥rio GitHub (`Settings > Secrets and variables > Actions`):

* `GCP_SA_KEY`: Conte√∫do JSON completo da chave da Service Account da GCP (com as permiss√µes necess√°rias).
* `GCP_PROJECT_ID`: O ID do seu projeto GCP.
* `DB_NAME_SECRET`: Nome do banco de dados PostgreSQL.
* `DB_USER_SECRET`: Usu√°rio do banco de dados PostgreSQL.
* `DB_PASSWORD_SECRET`: Senha do banco de dados PostgreSQL.

### Permiss√µes da Service Account da GCP

A Service Account usada pelo GitHub Actions (`GCP_SA_KEY`) e a Service Account usada pelos servi√ßos Cloud Run em tempo de execu√ß√£o (`cloud-run-sa-...`) precisam das seguintes permiss√µes no seu projeto GCP:

* **Service Account do GitHub Actions (para o pipeline de CI/CD):**
    * `Cloud Run Admin`
    * `Artifact Registry Writer`
    * `Storage Object Viewer` (para baixar dados brutos)
    * `Storage Object Admin` (para fazer upload de modelos)
    * `Service Account User` (para atuar como a SA do Cloud Run)
    * `Cloud SQL Client` (se a Action precisar descrever inst√¢ncias SQL)
    * `Service Usage Consumer`
* **Service Account do Cloud Run (para os servi√ßos em execu√ß√£o):**
    * `Cloud SQL Client` (para conectar ao Cloud SQL)
    * `Storage Object Viewer` (para ler artefatos de modelo do GCS)

## üìä Monitoramento e Drift Detection

A stack de monitoramento √© composta por Prometheus e Grafana, que coletam m√©tricas dos servi√ßos da API e de Drift Monitor.

* **endpoint /feedback (servi√ßo de drift)**: Recebe o feedback com os dados reais de contrata√ß√£o para serem usados como insumos para os calculos de drift.

* **endpoint /metrics (servi√ßo de drift)**: Exp√µe as metricas de Drift Calculadas para o modelo

* **Prometheus**: Coleta m√©tricas de:
    * Requisi√ß√µes HTTP (`http_requests_total`, `http_request_duration_seconds`)
    * Lat√™ncia de predi√ß√£o (`prediction_duration_seconds`)
    * Erros de predi√ß√£o (`prediction_errors_total`)
    * N√∫mero de candidatos por requisi√ß√£o (`applicants_per_prediction_request`)
    * Vers√£o do modelo (`model_version`)
    * M√©tricas de Drift (`data_drift_score`, `concept_drift_score`, `model_f1_score_production`, etc.)
* **Grafana**: Permite criar dashboards personalizados para visualizar essas m√©tricas, identificar tend√™ncias, anomalias e receber alertas sobre o desempenho da aplica√ß√£o e a sa√∫de do modelo.

## ü§ù Contribui√ß√£o

Contribui√ß√µes s√£o bem-vindas! Siga estas diretrizes:

1.  Fa√ßa um fork do reposit√≥rio.
2.  Crie uma nova branch para sua feature (`git checkout -b feature/minha-nova-feature`).
3.  Fa√ßa suas altera√ß√µes e certifique-se de que os testes passem.
4.  Execute `pre-commit run --all-files` antes de commitar.
5.  Envie suas altera√ß√µes (`git push origin feature/minha-nova-feature`).
6.  Abra um Pull Request.

## üìÑ Licen√ßa

Este projeto est√° licenciado sob a licen√ßa MIT. Consulte o arquivo LICENSE para mais detalhes.
